### 캐시 메모리 란?

- CPU의 작업 처리 속도가 주기억장치의 접근 속도보다 매우 빨라서 나온 SRAM 기반 메모리
- CPU와 주기억장치 사이에 위치하며 접근 속도가 주기억장치보다 훨씬 빠름
- CPU의 사용률이 주기억장치 접근 속도 때문에 손해를 보기에 그것을 메꾸어주려고 나온 메모리

<br><br><br>

### 참조 지역성의 원리

- 캐시 메모리는 메모리보다 용량이 적다
- 당연하게도 메모리의 모든 내용을 저장할 수 없다
- CPU가 자주 사용할 법한 내용을 예측해서 캐시 메모리에 저장하자.
- 캐시 히트 : 예측이 들어맞았을 경우, 주기억장치를 탐색하지 않아도 됨
- 캐시 미스 : 예측이 들어맞지 않았을 경우, 주기억장치를 추가적으로 탐색해야 함

#### 시간적 지역성

- 특정 데이터에 한 번 접근했을 경우, 가까운 미래에 또 한 번 데이터에 접근할 가능성이 높다.
- for문과 같은 반복문이나 함수 호출에 의해서 한번 더 호출될 수 있음

#### 공간적 지역성

- 특정 데이터에 한 번 접근했을 경우, 가까운 곳에 위치한 데이터에 접근할 가능성이 높다.
- 캐시 메모리는 어떠한 메모리에 접근할 때 해당 메모리 뿐만 아니라 해당 메모리가 포함된 블록을 들고온다.
- 배열과 같은 데이터는 연속된 논리적 주소에 데이터가 적재된다.

#### 순차적 지역성

- 데이터가 메모리에 저장된 순서대로 호출될 가능성이 높다.

<br><br><br>

### 파레토의 법칙

- 전체의 20%가 80%의 결과를 발생시킨다.

<br><br><br>

### 캐시 교체 알고리즘

#### LRU

- Least Recently Used
- 가장 오랫동안 사용되지 않은 메모리를 제거
- 내부적으로 LinkedList + HashMap으로 구현되어있음

#### LFU

- Least Frequently Used
- 가장 빈번하게 사용되지 않은 메모리를 제거

#### FIFO

- First In First Out
- 가장 먼저 들어온 메모리를 제거